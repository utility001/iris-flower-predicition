{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn our model into a serverless prediction service that is going to run  by itself, generate predictions by itself and use its user interface to show predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2kLrOh-bpGy"
   },
   "source": [
    "# Iris Flower - Feature Pipeline\n",
    "\n",
    "In this notebook we will, \n",
    "\n",
    "1. Run in either \"Backfill\" or \"Normal\" operation. \n",
    "2. IF *BACKFILL==True*, we will load our DataFrame with data from the iris.csv file \n",
    "\n",
    "   ELSE *BACKFILL==False*, we will load our DataFrame with one synthetic Iris Flower sample \n",
    "3. Write our DataFrame to a Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "BACKFILL=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is backfill and what do we use it for?\n",
    "\n",
    "Set **BACKFILL=True** if you want to create features from the iris.csv file containing historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function for creating synthetic data. \n",
    "This function will be run from time to time in order to generate a dataframe containing a single iris flower sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nRmFM7vcbpHA",
    "outputId": "d920d168-9818-40c5-c292-4cf0afcbbcfd"
   },
   "outputs": [],
   "source": [
    "def generate_new_iris_flower(name, sepal_len_max, sepal_len_min, sepal_width_max, \n",
    "                             sepal_width_min, petal_len_max, petal_len_min,\n",
    "                             petal_width_max, petal_width_min):\n",
    "    \"\"\"\n",
    "    Returns a single iris flower as a single row in a DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({ \"sepal_length\": [random.uniform(sepal_len_max, sepal_len_min)],\n",
    "                       \"sepal_width\": [random.uniform(sepal_width_max, sepal_width_min)],\n",
    "                       \"petal_length\": [random.uniform(petal_len_max, petal_len_min)],\n",
    "                       \"petal_width\": [random.uniform(petal_width_max, petal_width_min)]\n",
    "                      })\n",
    "    df['species'] = name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nRmFM7vcbpHA",
    "outputId": "d920d168-9818-40c5-c292-4cf0afcbbcfd"
   },
   "outputs": [],
   "source": [
    "def get_random_iris_flower():\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing one random iris flower\n",
    "    \"\"\"\n",
    "    setosa_df =  generate_new_iris_flower(\"setosa\", 5.8, 4.3, 4.5, 2.3, 1.9, 1, 2.5, 0.1)\n",
    "    versicolor_df = generate_new_iris_flower(\"versicolor\", 7, 4.9, 3.4, 2.0, 5.1, 3, 1.8, 1.0)\n",
    "    virginica_df = generate_new_iris_flower(\"virginica\", 7.9, 4.9, 3.8, 2.2, 6.9, 4.5, 2.5, 1.4)\n",
    "    \n",
    "    # randomly pick one of these 3 and write it to the featurestore\n",
    "    pick_random = random.uniform(0,3)\n",
    "    if pick_random >= 2:\n",
    "        iris_df = virginica_df\n",
    "    elif pick_random >= 1:\n",
    "        iris_df = versicolor_df\n",
    "    else:\n",
    "        iris_df = setosa_df\n",
    "\n",
    "    return iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.399762</td>\n",
       "      <td>3.089884</td>\n",
       "      <td>1.799603</td>\n",
       "      <td>1.456563</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0      5.399762     3.089884      1.799603     1.456563  setosa"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_iris_flower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backfill or create new synthetic input data\n",
    "\n",
    "This pipeline can be run in either backfill or synthetic data mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from sklearn dataset\n",
    "def get_iris():\n",
    "    \"\"\"\n",
    "    This function loads the iris dataset from sklearn datasets\n",
    "    \"\"\"\n",
    "    # Load dataset, get the featues and labels\n",
    "    dataset = load_iris(as_frame=True)\n",
    "    feature=dataset.data\n",
    "    label=dataset.target\n",
    "\n",
    "    # Merge the featues and labels into one dataframe\n",
    "    df = feature.copy()\n",
    "    df[\"species\"] = label\n",
    "\n",
    "    # Convert the target into acutal classes\n",
    "    target = {\n",
    "        0: \"setosa\",\n",
    "        1: \"versicolor\",\n",
    "        2: \"virginica\"\n",
    "    }\n",
    "    \n",
    "    df['species'] = df[\"species\"].map(target)\n",
    "\n",
    "    rename_col = {\n",
    "        \"sepal length (cm)\": \"sepal_length\",\n",
    "        \"sepal width (cm)\": \"sepal_width\",\n",
    "        \"petal length (cm)\": \"petal_length\",\n",
    "        \"petal width (cm)\": \"petal_width\"\n",
    "    }\n",
    "    df = df.rename(columns=rename_col)\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.190488</td>\n",
       "      <td>3.051881</td>\n",
       "      <td>4.700561</td>\n",
       "      <td>1.441109</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0      5.190488     3.051881      4.700561     1.441109  versicolor"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if BACKFILL == True:\n",
    "    # iris_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/iris.csv\")\n",
    "    iris_df = get_iris()    \n",
    "else:\n",
    "    iris_df = get_random_iris_flower()\n",
    "    \n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate with Hopsworks using your API Key\n",
    "\n",
    "Hopsworks will prompt you to paste in your API key and provide you with a link to find your API key if you have not stored it securely already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is hopsworks api key\n",
    "It is a credential that allows users to interact with the hopsworks pltform without needing username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/70809\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and write to a feature group - primary keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent duplicate entries, Hopsworks requires that each DataFame has a *primary_key*.   \n",
    "A *primary_key* is one or more columns that uniquely identify the row. Here, we assume  \n",
    "that each Iris flower has a unique combination of (\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\")  \n",
    "feature values. If you randomly generate a sample that already exists in the feature group, the insert operation will fail.\n",
    "\n",
    "The *feature group* will create its online schema using the schema of the Pandas DataFame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b44281072634bc3adb3dcb13263a678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sklearn_iris_dataset_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/70809/jobs/named/sklearn_iris_dataset_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fabad72e6e0>, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_fg = fs.get_or_create_feature_group(name=\"sklearn_iris_dataset\",\n",
    "                                  version=1,\n",
    "                                  primary_key=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
    "                                  description=\"Iris flower dataset from sklearn datasets\"\n",
    "                                 )\n",
    "iris_fg.insert(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the job finishes running before you move to next step"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
